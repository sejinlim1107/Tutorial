{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "VrvPIyiC4tVY"
      },
      "outputs": [],
      "source": [
        "# MNIST and Deep learning CNN\n",
        "import torch\n",
        "import torchvision.datasets as datasets # 이미지 관련 파이토치 라이브러리\n",
        "import torchvision.transforms as transforms # 전처리 기능 제공하는 라이브러리\n",
        "import torch.nn as nn # torch 내의 세부적인 기능 불러오기 (신경망 기술, 손실함수 등)\n",
        "import torch.nn.functional as F # 신경망 기술\n",
        "import torch.optim as optim # 최적화 문제\n",
        "import matplotlib.pyplot as plt # 시각화 도구"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tguYgON4tVb",
        "outputId": "b94c43d3-5dbe-42ba-9354-bbb4db7444ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 is available.\n"
          ]
        }
      ],
      "source": [
        "# CPU/GPU\n",
        "# GPU 쓰려구. CNN은 GPU에서 효율적인 연산 가능\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'{device} is available.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "L13LR7RP4tVb"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 5\n",
        "batch_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "Wr6QY1f24tVc"
      },
      "outputs": [],
      "source": [
        "# MNIST dataset\n",
        "mnist_train = datasets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = datasets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플(tuple) 형태 (이미지, 라벨)\n",
        "# mnist_train[0]은 학습 데이터의 첫 번째 데이터로 이미지 한 장과 라벨 숫자 하나가 저장되어 있음\n",
        "# 즉, mnist_train[0][0]은 이미지이며 mnist_train[0][1]은 라벨임\n",
        "print(mnist_train.classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyXhfQNvRV3Q",
        "outputId": "8d7c242c-b141-4203-88ff-b57687223d97"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mnist_train[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn3JDoI7RjDw",
        "outputId": "78146c5b-782c-45e8-ec3c-a5b5c4dd8529"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.1647, 0.4627, 0.8588, 0.6510, 0.4627,\n",
            "          0.4627, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.4039, 0.9490, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0706, 0.9098, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9333, 0.2745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4078, 0.9569, 0.9961, 0.8784, 0.9961,\n",
            "          0.9961, 0.9961, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.8118, 0.9961, 0.8235, 0.9961,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.3294, 0.8078, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.1608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8196, 0.9961,\n",
            "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.3569, 0.5373, 0.9922, 0.9961,\n",
            "          0.9961, 0.9961, 0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.1569, 0.8392, 0.9804, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.3176, 0.9686, 0.9961, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.5725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.4314, 0.9647, 0.9961, 0.9961, 0.9961,\n",
            "          0.9961, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.2863, 0.3490, 0.3490, 0.3647,\n",
            "          0.9412, 0.9961, 0.6706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
            "          0.5020, 0.9961, 0.8588, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0275,\n",
            "          0.9961, 0.9961, 0.8392, 0.1098, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5412,\n",
            "          0.9961, 0.9961, 0.4549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0745, 0.6941,\n",
            "          0.3529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0980, 0.9412,\n",
            "          0.9961, 0.9961, 0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.9961,\n",
            "          0.8431, 0.2471, 0.1412, 0.0000, 0.2000, 0.3490, 0.8078, 0.9961,\n",
            "          0.9961, 0.5451, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.7725,\n",
            "          0.9961, 0.9961, 0.8706, 0.7059, 0.9451, 0.9961, 0.9961, 0.9922,\n",
            "          0.8353, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5490,\n",
            "          0.4118, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9961, 0.9255,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0275, 0.4588, 0.4588, 0.6471, 0.9961, 0.9961, 0.9373, 0.1961,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "          0.0000, 0.0000, 0.0000, 0.0000]]]), 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "lJVlW7TC4tVc"
      },
      "outputs": [],
      "source": [
        "# DataLoader는 데이터를 미니 배치 형태로 만들어 줌\n",
        "# 따라서 배치 사이즈 및 셔플 여부 등을 선택할 수 있음\n",
        "# 여기서 배치 사이즈는 한번 학습을 할 때마다 이미지가 100개씩 들어감을 의미\n",
        "train_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter = iter(train_loader)\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "print(images.size())\n",
        "print(labels) # 배치크기 X 채널 수 X 너비 X 높이 "
      ],
      "metadata": {
        "id": "EbRsi7_0kfgO",
        "outputId": "f8d890ae-ffa2-4488-922a-09f093905856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28])\n",
            "tensor([2, 3, 1, 9, 7, 4, 0, 5, 8, 1, 2, 7, 7, 1, 2, 8, 6, 0, 2, 0, 7, 9, 5, 1,\n",
            "        5, 0, 2, 3, 9, 6, 7, 9, 7, 6, 6, 0, 3, 6, 0, 2, 0, 1, 2, 3, 0, 0, 7, 8,\n",
            "        7, 6, 1, 3, 5, 1, 5, 0, 0, 1, 4, 5, 5, 4, 8, 8, 4, 6, 6, 8, 9, 3, 1, 4,\n",
            "        9, 4, 4, 7, 2, 7, 4, 7, 9, 6, 1, 9, 3, 7, 0, 2, 3, 5, 4, 1, 0, 2, 4, 4,\n",
            "        9, 6, 4, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
        "        #    Conv      ->(?, 7, 7, 128)\n",
        "        #    Pool      ->(?, 4, 4, 128)\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2, padding=1))\n",
        "\n",
        "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
        "        self.fc1 = nn.Linear(4 * 4 * 128, 625, bias=True)\n",
        "        \n",
        "        self.layer4 = nn.Sequential(\n",
        "            self.fc1,\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5))\n",
        "        \n",
        "        # L5 Final FC 625 inputs -> 10 outputs\n",
        "        self.fc2 = nn.Linear(625, 10, bias=True)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        \n",
        "        out = out.view(out.size(0), -1) # Flatten them for FC\n",
        "        # 일렬로 핀 개수가 배치 수만큼 있어야하니까 out.size(0)\n",
        "\n",
        "        out = self.layer4(out)\n",
        "        out = self.fc2(out)\n",
        "        # CrossEntropyLoss는 softmax 계산까지 포함되어 있으므로 모델의 마지막 output node에 별도의 활성화 함수를 사용하지 않아도 됨\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "B0JcmpYYnC-g"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "kSC9X6oY4tVe"
      },
      "outputs": [],
      "source": [
        "# CNN 모델 선언\n",
        "# GPU 연산을 할 수 있도록 반드시 to(device)를 써줘야함\n",
        "model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "wgrm-uI4rVCx",
        "outputId": "d79a4c7e-e24d-495c-e150-e1d376e2d700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc1): Linear(in_features=2048, out_features=625, bias=True)\n",
            "  (layer4): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=625, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            "  (fc2): Linear(in_features=625, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "5PHLfYqE4tVf"
      },
      "outputs": [],
      "source": [
        "# loss 함수, 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss().to(device) # 다중 분류 문제라서 사용. softmax 계산까지 포함됨\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # 업데이트 되어야하는 파라미터 첫번째 인자로 넘겨주기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader) # 학습 이미지가 60,000장이고 배치 사이즈가 100장이므로 총 배치의 개수는 600개"
      ],
      "metadata": {
        "id": "I8KippAhl4ds",
        "outputId": "f7f5bbf4-f250-47b3-e8a9-843aca9038ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzeEnukV4tVf",
        "outputId": "b84ca271-dba2-428b-9676-ea9966fc2ff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!학습 시작!\n",
            "[Epoch:  1] loss = 0.141101345\n",
            "[Epoch:  2] loss = 0.0460718535\n",
            "[Epoch:  3] loss = 0.0364060514\n",
            "[Epoch:  4] loss = 0.0300667547\n",
            "[Epoch:  5] loss = 0.0254511312\n",
            "!학습 끝!\n"
          ]
        }
      ],
      "source": [
        "loss_ = [] # 그래프를 그리기 위한 loss 저장용 리스트 \n",
        "total_batch = len(train_loader) # 총 배치 수\n",
        "model.train()    # set the model to train mode (dropout=True)\n",
        "print('!학습 시작!')\n",
        "for epoch in range(training_epochs): # 5번 학습 진행\n",
        "    avg_loss = 0\n",
        "\n",
        "    for X, Y in train_loader:\n",
        "        X = X.to(device) # GPU용 데이터(텐서)로 바꿔주기\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # 옵티마이저 초기화\n",
        "        output = model(X) # 예측값 산출\n",
        "        loss = criterion(output, Y) # 손실함수 계산\n",
        "        loss.backward() # 손실함수 기준으로 역전파\n",
        "        optimizer.step() # 가중치 최적화\n",
        "\n",
        "        avg_loss += loss / total_batch\n",
        "\n",
        "    print('[Epoch: {:>2}] loss = {:>.9}'.format(epoch + 1, avg_loss))\n",
        "    loss_.append(avg_loss.item()) # loss는 tensor 형태이기 때문에 item() 함수를 통해 숫자만 가져옴\n",
        "\n",
        "print('!학습 끝!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_"
      ],
      "metadata": {
        "id": "pMqNnGyVc1Vb",
        "outputId": "dd20f604-f396-4554-e60b-cd0ae743912c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14110134541988373,\n",
              " 0.0460718534886837,\n",
              " 0.036406051367521286,\n",
              " 0.030066754668951035,\n",
              " 0.02545113116502762]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7IhI19vQcJY5",
        "outputId": "511bf8e7-2820-4f59-e465-9f67efbcc097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDk224CW4tVg",
        "outputId": "719a99f5-9b39-47cc-bb03-b2345a241eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9788999557495117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:80: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:70: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ]
        }
      ],
      "source": [
        "# Test model and check accuracy\n",
        "with torch.no_grad():\n",
        "    model.eval()    # 모델을 평가모드로 설정 (dropout=False)\n",
        "\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    # prediction에는 10개의 라벨에 대한 벡터 값들이 나타나있으므로 그 중 가장 큰 값 선택해야함\n",
        "    # torch.argmax(prediction, 1)의 결과는 최댓값의 위치를 나타냄\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "lab-10_2_mnist_deep_cnn.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}